{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excessive-listening",
   "metadata": {},
   "source": [
    "## In this assignment, we will get acquainted with essential matrix and fundamental matrix. And recover the essential matrix from matched points of two scene with OpenCV. Furthermore, we will try to localize these matched points in the 3D space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaptive-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read matched points from two scenes\n",
    "\n",
    "import pickle\n",
    "with open('data_points.pickle','rb') as handle:\n",
    "    data=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "spoken-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find fundamental matrix from the match points using OpenCV\n",
    "import cv2\n",
    "\n",
    "pts1 = data['x1']\n",
    "pts2 = data['x2']\n",
    "\n",
    "F, mask = cv2.findFundamentalMat(pts1,pts2,cv2.FM_8POINT)\n",
    "pts1 = pts1[mask.ravel()==1] # remove outliers by only keeping inliers\n",
    "pts2 = pts2[mask.ravel()==1] # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "governing-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Find\" essential matrix\n",
    "import numpy as np\n",
    "\n",
    "K = np.eye(3) # Take the camera intrisic matrix matrix K to be identity. \n",
    "E = K.T @ F @ K # The essential matrix is just the same as the fundamental matrix when K = I\n",
    "\n",
    "#E, mask = cv2.findEssentialMat(pts1,pts2,K,cv2.RANSAC) # alternatively, we may try to find essential matrix directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faced-significance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.112964470057932e-09"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check of the essential matrix\n",
    "import numpy as np\n",
    "\n",
    "hx1=np.hstack((pts1,np.ones((2000,1))))\n",
    "hx2=np.hstack((pts2,np.ones((2000,1))))\n",
    "\n",
    "rint=np.random.randint(hx1.shape[0])\n",
    "hx2[rint].T @ E @hx1[rint] # this should be almost zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-scope",
   "metadata": {},
   "source": [
    "# Q1 (5 points) Compute a potential solution of R and t from E. Note that you will only get half of the points if you use cv2.decomposeEssentialMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "initial-distinction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after function\n",
      "[[-1.03683043e-06  1.06902165e+02 -1.06902143e+02]\n",
      " [-1.06902191e+02  5.18415326e-07 -4.75654139e-07]\n",
      " [ 1.06902169e+02 -5.61176299e-07  5.18415104e-07]]\n",
      "[-5.61176299e-07 -1.06902143e+02 -1.06902191e+02]\n",
      "[[-1.00000000e+00  4.81185127e-09  4.83671535e-09]\n",
      " [ 4.81185201e-09  1.00000000e+00  2.41656764e-07]\n",
      " [-4.83671427e-09  2.41656763e-07 -1.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.27057869e-14,  1.27897692e-13,  8.52651283e-14],\n",
       "       [-2.84217094e-14, -1.77306582e-14,  4.17691591e-14],\n",
       "       [ 5.68434189e-14,  3.63381851e-14, -1.51087805e-14]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# this function should be helpful. You probably want to call the function below instead of np.linalg.svd\n",
    "def mySVD(E): # compute SVD E = U S V and enforcing det(U)=det(V)=1\n",
    "    U,S,V = np.linalg.svd(E)\n",
    "    detU=np.linalg.det(U)\n",
    "    detV=np.linalg.det(V)\n",
    "    U=U/detU\n",
    "    V=V/detV\n",
    "    S=S*detU*detV\n",
    "    return U,S,V\n",
    "\n",
    "def compute_one_R_and_t_from_E(E):\n",
    "    # Input:\n",
    "        # E: essential matrix\n",
    "    # Output:\n",
    "        # R: rotation matrix (3x3)\n",
    "        # t: translation (3x1)\n",
    "    W = np.array([[0,-1,0],[1,0,0],[0,0,1]])\n",
    "    U, L, VT = mySVD(E)\n",
    "    \n",
    "    #from Simon J. D Prince CV Text book equations 16.18 and 16.19\n",
    "    tx = U @ np.diag(L) @ W @ np.transpose(U)\n",
    "    t = np.array([tx[2,1],tx[0,2],tx[1,0]])\n",
    "    R = U @ np.linalg.inv(W) @ (VT)\n",
    "    \n",
    "    return R,t,tx\n",
    "\n",
    "print(\"after function\")\n",
    "R,t,tx = compute_one_R_and_t_from_E(E)\n",
    "print(tx)\n",
    "print(t)\n",
    "print(R)\n",
    "tx@R-E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-carol",
   "metadata": {},
   "source": [
    "## Testing solution of Q.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "lucky-flexibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.07094076e-06  5.15660889e-05 -2.13804313e+02]\n",
      " [-2.58336291e-05 -5.18415173e-07 -5.37775929e-09]\n",
      " [ 2.13804338e+02  2.65792495e-09 -5.15695396e-07]]\n",
      "[[-1.27057869e-14  1.27897692e-13  8.52651283e-14]\n",
      " [-2.84217094e-14 -1.77306582e-14  4.17691591e-14]\n",
      " [ 5.68434189e-14  3.63381851e-14 -1.51087805e-14]]\n"
     ]
    }
   ],
   "source": [
    "R,t,txt = compute_one_R_and_t_from_E(E)\n",
    "\n",
    "tx= np.array([[0,t[2],-t[1]],\n",
    "              [-t[2],0,t[0]],\n",
    "              [t[1],-t[0],0]])\n",
    "print(R@tx-E) # this should be almost 0\n",
    "print(txt@R-E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-carol",
   "metadata": {},
   "source": [
    "# Q2.a (5 points) For two lines ${\\bf a_1} + \\lambda_1 {\\bf b_1}$ and ${\\bf a_2} + \\lambda_2 {\\bf b_2}$ in the 3-D space parametrized by $\\lambda_1$ and $\\lambda_2$ (${\\bf a_1}, {\\bf a_2}, {\\bf b_1}, {\\bf b_2}$ are length-$3$ vectors). Find the intersecting point between the two lines (the mid point between the closest points of the two lines) by derivating the expressions of the optimum $\\lambda_1$ and $\\lambda_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-comparative",
   "metadata": {},
   "source": [
    "# Q2.b (5 points) Implement the solution of Q2.a by completing the function below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "linear-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIntersection(a1,b1,a2,b2):\n",
    "    # Input:\n",
    "        # a1: Nx3 matrix  (a1[i] = ith a1)\n",
    "        # b1: Nx3 matrix  (b1[i] = ith b1)\n",
    "        # a2: Nx3 matrix  (a2[i] = ith a2)\n",
    "        # b2: Nx3 matrix  (b2[i] = ith b2)\n",
    "        # N.B. for the ith pair of lines, line 1: a1[i]+lambda1[i] b1[i] and line 2: a2[i]+lambda2[i] b2[i]\n",
    "    # Output:\n",
    "        # points: Nx3 matrix (points[i] = the intersecting point for ith pair)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-arlington",
   "metadata": {},
   "source": [
    "## Testing solution of Q2.b\n",
    "#### We will take camera center of view 1 as origin, so ${\\bf a_1} = {\\bf 0}$, ${\\bf b_1} = [x_1[0],x_1[1],1]^\\top$\n",
    "#### And ${\\bf a_2} = {\\bf t}$, $b_2 = R [x_2[0],x_2[1],0]^\\top$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "color-representation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  -0.28687998,    1.8775782 , -109.14884922],\n",
       "        [  -0.23945037,    0.40417965, -109.63699108],\n",
       "        [  -0.37123112,    0.47409453, -109.60449159],\n",
       "        ...,\n",
       "        [  -0.61579632,    0.89345589, -107.63380911],\n",
       "        [  -0.84394685,    0.97585321, -107.6415475 ],\n",
       "        [  -0.7574854 ,    1.42514355, -107.67678137]]),\n",
       " array([[  0.28687946,  -2.24669299, 105.02460402],\n",
       "        [  0.23944984,  -2.73483479, 106.49800259],\n",
       "        [  0.37123059,  -2.70233531, 106.42808771],\n",
       "        ...,\n",
       "        [  0.6157958 ,  -0.73165284, 106.00872628],\n",
       "        [  0.84394633,  -0.73939123, 105.92632896],\n",
       "        [  0.75748488,  -0.77462512, 105.47703862]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.zeros((pts1.shape[0],3))\n",
    "b1 = np.hstack((pts1,np.ones((pts1.shape[0],1))))\n",
    "a2 = np.tile(t,(pts1.shape[0],1))\n",
    "b2 = np.hstack((pts2,np.ones((pts2.shape[0],1))))\n",
    "b2 = (R.T @ b2.T).T\n",
    "\n",
    "Xs=computeIntersection(a1,b1,a2,b2) # 3D coordinates of points in the first camera view\n",
    "Xps=(R@(Xs-t).T).T # 3D coordinates of points in the second camera view\n",
    "Xs,Xps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-filename",
   "metadata": {},
   "source": [
    "# Chirality\n",
    "\n",
    "### Note that Xs and Xps are the points in the 3D space with camera centers as origins and with z-axis pointing from the camera centers to the objects. So the z-component (third column of Xs and Xps) should be both non-negative because the object points suppose to be in front of the cameras. But with only 1/4 of the chance you would be lucky. Because there are four possible combinations of R and t and only one is correct (satisfies chirality).\n",
    "\n",
    "# Q2.c (4 points) Find the correct R and t by adjusting your solution in Q1. It is okay to provide a \"buggy\" solution that only works for the current dataset. Please redefine compute_one_R_and_t_from_E(E) below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "enclosed-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# this function should be helpful. You probably want to function below instead of np.linalg.svd\n",
    "def mySVD(E): # compute SVD E = U S V and enforcing det(U)=det(V)=1\n",
    "    U,S,V = np.linalg.svd(E)\n",
    "    detU=np.linalg.det(U)\n",
    "    detV=np.linalg.det(V)\n",
    "    U=U/detU\n",
    "    V=V/detV\n",
    "    S=S*detU*detV\n",
    "    return U,S,V\n",
    "\n",
    "def compute_one_R_and_t_from_E(E):\n",
    "    # Input:\n",
    "        # E: essential matrix\n",
    "    # Output:\n",
    "        # R: rotation matrix (3x3)\n",
    "        # t: translation (3x1)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "united-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.238334793184919e-07"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rerun everything below\n",
    "\n",
    "R,t = compute_one_R_and_t_from_E(E)\n",
    "\n",
    "tx= np.array([[0,t[2],-t[1]],[-t[2],0,t[0]],[t[1],-t[0],0]])\n",
    "rint=np.random.randint(hx1.shape[0])\n",
    "hx2[rint].T @ R@tx @hx1[rint] # this should be almost zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "quiet-collectible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.28687998,  -1.8775782 , 109.14884922],\n",
       "        [  0.23945037,  -0.40417965, 109.63699108],\n",
       "        [  0.37123112,  -0.47409453, 109.60449159],\n",
       "        ...,\n",
       "        [  0.61579632,  -0.89345589, 107.63380911],\n",
       "        [  0.84394685,  -0.97585321, 107.6415475 ],\n",
       "        [  0.7574854 ,  -1.42514355, 107.67678137]]),\n",
       " array([[  0.28687946,  -2.24669299, 105.02460402],\n",
       "        [  0.23944984,  -2.73483479, 106.49800259],\n",
       "        [  0.37123059,  -2.70233531, 106.42808771],\n",
       "        ...,\n",
       "        [  0.6157958 ,  -0.73165284, 106.00872628],\n",
       "        [  0.84394633,  -0.73939123, 105.92632896],\n",
       "        [  0.75748488,  -0.77462512, 105.47703862]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = np.zeros((pts1.shape[0],3))\n",
    "b1 = np.hstack((pts1,np.ones((pts1.shape[0],1))))\n",
    "a2 = np.tile(t,(pts2.shape[0],1))\n",
    "b2 = np.hstack((pts2,np.ones((pts2.shape[0],1))))\n",
    "b2 = (R.T @ b2.T).T\n",
    "\n",
    "Xs=computeIntersection(a1,b1,a2,b2)\n",
    "Xps=(R@(Xs-t).T).T \n",
    "Xs,Xps # note that third third columns should be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "descending-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00262833 -0.017202  ] [ 0.00262834 -0.017202    1.        ]\n",
      "[ 0.00273155 -0.02139206] [ 0.00273155 -0.02139206  1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: the projection to cameras should get back the original\n",
    "\n",
    "print(pts1[0],Xs[0]/Xs[0,2]) # the numbers should match if you did correctly\n",
    "print(pts2[0],Xps[0]/Xps[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "applicable-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install open3d # install open3d if you don't have it installed before\n",
    "# visualize your point cloud\n",
    "\n",
    "import open3d as o3d\n",
    "\n",
    "cloud=o3d.geometry.PointCloud(o3d.utility.Vector3dVector(Xps)) \n",
    "o3d.visualization.draw_geometries([cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-radiation",
   "metadata": {},
   "source": [
    "# Q2.d (1 point): What is the object that you are seeing? Click the screen and move the mouse around and you can rotate it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-optimization",
   "metadata": {},
   "source": [
    "# Q3 (10 points, extra credit): Capture two images and try to reconstruct 3D shape with the tools you developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-reflection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-omega",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-orientation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-appointment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-couple",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
